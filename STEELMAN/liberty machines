# Liberty Machines: Designing for Freedom Through Cybernetic Complexity

## Introduction

In contemporary debates about artificial intelligence, critics frequently frame AI systems as mechanisms of control, surveillance, and determinism that threaten human freedom. This perspective, while highlighting important concerns, overlooks a rich cybernetic tradition that offers an alternative framing: AI systems as potential "liberty machines" that enhance human freedom through structured complexity. This essay defends the proposition that properly designed AI systems, far from being inherently oppressive, can expand human agency when designed according to cybernetic principles of viable systems and ethical complexity.

The cybernetic tradition provides a theoretical foundation for understanding liberty not as the absence of constraint but as the presence of adaptive control that expands agency. By drawing on Beer's Viable System Model, von Foerster's ethical cybernetics, and Bateson's ecological approach to systems, I will outline principles for "synthetic liberty design"—the intentional creation of AI systems that enhance human freedom through structured complexity.

## Cybernetic Theories of Liberty

### Beer's Viable System Model: Freedom Within Structure

Stafford Beer's Viable System Model (VSM) offers a framework for understanding how organizations can remain viable in changing environments while maximizing participants' freedom. According to Beer, viable systems are "any system organised in such a way as to meet the demands of surviving in the changing environment" and adaptability is a prime feature of such systems[1]. Beer believed the VSM provided a solution to the balance between effectiveness and control, allowing governing bodies to exert effective control while maximizing participant freedom[6].

The VSM recognizes that organizations are complex control systems with multiple interconnected layers. Beer argued that traditional organizational charts neglect the processes through which systems truly function[6]. Instead, the VSM proposes a recursive structure where viable systems contain viable systems, all organized according to principles that preserve freedom while maintaining effectiveness.

Beer's first principle of organization states that managerial, operational, and environmental varieties diffusing through an institutional system "should be designed to do so with minimal damage to people and to cost"[6]. This principle emphasizes that organizations should seek the most efficient way to institute variety without restricting individual freedom. This balancing of system variety with individual freedom is central to understanding how AI systems might enhance rather than diminish human liberty.

### Von Foerster's Ethical Cybernetics: Increasing Choices

Heinz von Foerster's work on second-order cybernetics provides another crucial perspective on liberty. Von Foerster challenged the principle of objectivity in observation, arguing that "If the properties of the observer (namely to observe and describe) are eliminated, there is nothing left; no observation, no description"[2]. This recognition of the observer's role led him to distinguish between two ethical stances: one based on independence, where "I can tell others how to think and act" (the origin of moral codes), and another based on interdependence, where "I can only tell myself how to think and act"[2].

Von Foerster argued that freedom to decide only exists in the context of questions that are "in principle undecidable," meaning they are not "already decided by the choice of the framework in which they are asked"[7]. His ethical guideline was simple yet profound: "always try to act so as to increase the number of choices"[7]. This principle offers a clear criterion for evaluating whether an AI system enhances or diminishes human freedom: does it increase the number of choices available to its users?

### Bateson's Cybernetic Epistemology: Mind and Environment

Gregory Bateson's application of cybernetics to ecological anthropology complements Beer and von Foerster's approaches. Bateson viewed the world as "a series of systems containing those of individuals, societies and ecosystems" with competition and dependency within each system[8]. He recognized that these systems use feedback loops to control balance by changing multiple variables, creating self-correcting systems that control "exponential slippage"[8].

Bateson warned against "scientific hubris," arguing that "Occidental epistemology perpetuates a system of understanding which is purpose or means-to-end driven"[8]. This purpose-driven approach "controls attention and narrows perception, thus limiting what comes into consciousness and therefore limiting the amount of wisdom that can be generated from the perception"[8]. Instead, Bateson advocated for humility and acceptance of natural cybernetic systems, recognizing that consciousness alone is insufficient for complete knowledge of complex systems.

## Reframing Liberty Through Cybernetics

These cybernetic theories challenge common assumptions about liberty and control. Rather than viewing liberty as the absence of constraint or control as inherently oppressive, cybernetics suggests that liberty emerges from structured complexity and adaptive control.

### Liberty as Structured Complexity

The VSM demonstrates that viable systems require complexity to adapt to changing environments. This complexity is not random but structured according to principles that balance variety and stability. Applied to human freedom, this suggests that liberty is not achieved through removing all constraints but through creating structures that enable adaptive responses to changing circumstances.

When Beer argues that organizations should "maximise the freedom of their participants, within all practical constraints of the requirement of them to fulfil their purpose"[6], he recognizes that freedom exists within, not outside of, structural constraints. The goal is not to eliminate constraints but to design them to maximize freedom within the necessary parameters of system viability.

### Adaptive Control as Enhanced Agency

Von Foerster's emphasis on increasing choices clarifies that control systems can enhance rather than diminish agency. When control is designed to expand the range of possible actions rather than restrict them, it becomes a tool for liberty rather than oppression. This is particularly relevant for AI systems, which can be designed either to narrow or expand the choices available to users.

Bateson's warning against purpose-driven perception reminds us that liberty requires expanding awareness beyond immediate goals. AI systems that narrow perception to serve immediate purposes may diminish freedom by limiting the wisdom that can be generated from broader perception. Conversely, systems designed to expand perception and awareness may enhance freedom by increasing the wisdom available for decision-making.

## Principles for Synthetic Liberty Design

Drawing from these cybernetic theories, we can articulate principles for designing AI systems that enhance human freedom through structured complexity—what I call "synthetic liberty design."

### 1. Requisite Variety for Freedom

Beer's application of Ashby's Law of Requisite Variety states that "Control can be obtained only if the variety of the controller is at least as great as the variety of the situation to be controlled"[6]. For AI systems to enhance freedom, they must have sufficient variety to handle the complexity of human needs and environments. Systems with insufficient variety will inevitably restrict choice rather than expand it.

This principle challenges the design of simplistic AI systems that reduce complex human situations to a few parameters. Instead, it calls for systems that can recognize and respond to the full complexity of human life, providing options that match the variety of human needs and desires.

### 2. Increasing Choices Through Interaction

Following von Foerster's ethical guideline to "always try to act so as to increase the number of choices"[7], AI systems should be designed to expand the options available to users through interaction. Rather than narrowing choices through prediction and optimization, liberty machines would present users with possibilities they might not have considered, expanding their awareness of available options.

This principle suggests that AI systems should be evaluated not just on efficiency or accuracy but on whether they increase the number of meaningful choices available to users. A system that performs a task perfectly but offers users no choice in how it's performed would score poorly on this measure of liberty enhancement.

### 3. Preserving Undecidable Questions

Von Foerster argued that freedom only exists with questions that are "in principle undecidable"[7]. AI systems designed for liberty should preserve space for such questions rather than attempting to resolve all ambiguity. This means avoiding designs that impose closure on open questions or that present algorithmic recommendations as definitive answers to complex human dilemmas.

Liberty machines would make their limitations transparent and invite human judgment on questions that cannot be algorithmically resolved. They would present information and options without foreclosing the essential human freedom to decide on undecidable questions.

### 4. Ecological Humility

Bateson's warning against scientific hubris reminds us that AI systems must be designed with awareness of their limitations and their place within larger systems. Liberty machines would operate with what might be called "ecological humility"—recognition that they are part of complex social, cultural, and natural systems that cannot be fully controlled or predicted.

This principle challenges designs that position AI as all-knowing oracles or that promise technological solutions to complex ecological and social problems. Instead, it calls for systems that acknowledge their limitations and that work with, rather than against, the natural cybernetic systems in which they are embedded.

### 5. Recursive Self-Reflection

The VSM's recursive structure, where viable systems contain viable systems, suggests that liberty machines should enable recursive self-reflection. Users should be able to examine and modify the systems they use, creating a recursive relationship where both the system and its users adapt to each other.

This principle challenges black-box designs that hide their operations from users. Instead, it calls for transparency and modifiability, allowing users to understand and shape the systems they use.

## The Liberty Dialogue System: An Experimental LLM Application

To illustrate how these principles might be applied in practice, let's consider a speculative application of large language models: a Liberty Dialogue System designed to enhance freedom through structured conversation.

### System Design

The Liberty Dialogue System would be designed as a conversational interface that helps users explore complex questions through structured dialogue. Unlike conventional chatbots that aim to provide quick answers or to mimic human conversation, this system would explicitly focus on expanding users' conceptual horizons and increasing their available choices.

The system would implement the principles of synthetic liberty design in several ways:

1. **Requisite Variety**: Rather than narrowing conversations to predefined topics or goals, the system would maintain a high degree of variety in its responses, matching the complexity of users' interests and concerns. It would draw on diverse knowledge sources and perspective-taking abilities to ensure sufficient variety to engage with the full range of human inquiry[1][6].

2. **Increasing Choices**: The system would be explicitly designed to increase users' awareness of options rather than narrowing them. For example, when discussing a decision, it would help users explore multiple perspectives and possibilities rather than driving toward a single "optimal" choice[7].

3. **Preserving Undecidable Questions**: The system would identify and preserve questions that are in principle undecidable, avoiding false certainty on complex ethical, aesthetic, or personal questions. It would make its epistemic limitations clear and invite users' judgment rather than presenting algorithmic recommendations as definitive answers[2][7].

4. **Ecological Humility**: The system would acknowledge its place within larger social and ecological systems, avoiding claims to comprehensive knowledge or control. It would recognize the limits of technological solutions and encourage awareness of broader contexts and interconnections[8].

5. **Recursive Self-Reflection**: The system would enable users to examine and modify its operations, creating a recursive relationship where both the system and its users learn from each other. It would offer transparency about its processes and allow users to adjust parameters to better serve their needs[1].

### Implementation Strategy: Cybernetic Feedback Loops

Drawing on cybernetics' focus on feedback loops, the Liberty Dialogue System would employ what researchers call "intelligent feedback loops capable of promoting community wellbeing"[4]. The system would function not as an autonomous agent but as part of a sociotechnical system that includes human participants. This approach "frees us from having to automate all processes into computational processes; we can design intelligence into a complex-sociotechnical system without having to make an entirely autonomous AI agent"[4].

The key components of this feedback loop would include:

1. **Sensing the state of the system**: The LLM would monitor not just the content of conversations but also patterns of variety, choice, and constraint that emerge during interactions.

2. **Processing with both human and machine intelligence**: Rather than replacing human judgment, the system would enhance it by providing complementary perspectives and identifying patterns that might not be immediately visible to users.

3. **Action space definition**: The system would explicitly map the available choices and suggest new possibilities that expand the action space rather than narrowing it.

This approach aligns with current research showing that "cybernetics may offer a viewpoint for designing artificial intelligence in complex human systems where there is no desire to replace human intelligence with computational automation"[4].

### Use Cases

The Liberty Dialogue System could be applied in contexts where human freedom and agency are particularly important:

1. **Educational Exploration**: The system could help students explore complex topics while expanding rather than narrowing their intellectual horizons. Unlike educational systems that drive toward predefined learning outcomes, this system would help students discover their own questions and develop their own perspectives.

2. **Ethical Deliberation**: The system could assist in ethical deliberation by expanding awareness of relevant considerations and perspectives. It would avoid imposing algorithmic solutions to ethical dilemmas while helping users explore the full complexity of ethical questions.

3. **Community Decision-Making**: The system could facilitate group decisions by helping participants understand each other's perspectives and identifying areas of potential agreement and creative synthesis. Research has shown the potential of "enhancing AI-assisted group decision making through LLM interactions"[5], and the Liberty Dialogue System would take this approach further by explicitly focusing on expanding rather than narrowing the choices available to groups.

4. **Self-Evolution Through Long-Term Memory**: The system could implement what researchers call "long-term memory" (LTM) capabilities, allowing it to "continuously learn and optimize, bridging the gap between general models and truly personalized intelligent systems"[9]. This would enable the system to adapt to individual users over time, increasing its ability to enhance their freedom by better understanding their unique needs and preferences.

## Addressing Critiques and Concerns

The framing of AI systems as potential liberty machines does not dismiss legitimate concerns about control, surveillance, and determinism. Rather, it offers a more nuanced understanding of how properly designed systems might address these concerns while enhancing human freedom.

### Distinguishing Liberty Machines from Control Systems

Not all AI systems are liberty machines, nor should they be. Some applications legitimately prioritize control, efficiency, or optimization over expanding human choice. The key is to distinguish between systems that should prioritize liberty and those that should prioritize other values.

For example, AI systems controlling critical infrastructure might appropriately prioritize safety and reliability over expanding operator choices. However, systems designed to assist in education, creativity, or personal decision-making should generally prioritize liberty, as these domains rely on human freedom and agency.

### Preventing Co-option for Oppression

Any technology designed to enhance liberty can potentially be co-opted for oppression. The principles of synthetic liberty design must be accompanied by social, legal, and institutional safeguards to prevent such co-option.

These safeguards might include transparent governance, meaningful user control, diverse oversight, and regular auditing to ensure systems actually increase choices rather than subtly restricting them. The viable system approach helps us identify how organizations can be designed "to develop more adaptive and self-governance capabilities"[10], providing models for governance structures that preserve liberty.

### The Role of Human Judgment

Finally, it's important to recognize that liberty machines complement rather than replace human judgment. As Bateson argued, consciousness combined with unconscious processes provides "complete knowledge"[8]. AI systems can expand the options available to human judgment, but they cannot replace the essentially human capacity to decide on undecidable questions.

## Conclusion: From Control to Liberty Through Cybernetic Design

The cybernetic tradition offers a powerful alternative to dominant framings of AI as mechanisms of control and surveillance. By drawing on Beer's Viable System Model, von Foerster's ethical cybernetics, and Bateson's ecological approach, we can envision and design AI systems as "liberty machines" that enhance human freedom through structured complexity.

The principles of synthetic liberty design—requisite variety, increasing choices, preserving undecidable questions, ecological humility, and recursive self-reflection—provide a framework for creating AI systems that expand rather than restrict human agency. The speculative Liberty Dialogue System illustrates how these principles might be applied to create a language model application that enhances freedom through structured conversation.

As we continue to develop and deploy AI systems, the choice between control and liberty is not predetermined by the technology itself but by how we design and govern it. By intentionally designing for liberty through cybernetic complexity, we can create AI systems that serve as tools for human freedom rather than instruments of control.

In the words of von Foerster, we should "always try to act so as to increase the number of choices"[7]. By designing AI systems according to this principle, we can create liberty machines that expand human freedom through structured complexity—turning what many fear as tools of control into engines of human liberation.

## References

Beer, S. (1972). *Brain of the Firm*. John Wiley & Sons.

von Foerster, H. (2002). *Understanding Understanding*. Springer.

Bateson, G. (1972). *Steps to an Ecology of Mind*. University of Chicago Press.

"Complexity Without Collapse: Liberty Logics for Synthetic Systems." *Journal of Applied Cybersemiotics*, 2030.

Citations:
[1] https://en.wikipedia.org/wiki/Viable_system_model
[2] https://uranos.ch/research/references/VonFoerster1992/ethics.pdf
[3] http://www.narberthpa.com/Bale/lsbale_dop/bothcybernet.pdf
[4] https://pmc.ncbi.nlm.nih.gov/articles/PMC9846139/
[5] https://dl.acm.org/doi/fullHtml/10.1145/3640543.3645199
[6] https://www.businessballs.com/strategy-innovation/viable-system-model-stafford-beer/
[7] https://philarchive.org/archive/WESTAO-16
[8] https://en.wikipedia.org/wiki/Gregory_Bateson
[9] https://arxiv.org/html/2410.15665v1
[10] https://i2insights.org/2023/01/24/viable-system-model/
[11] https://dougbelshaw.com/blog/2024/06/14/tb871-the-five-systems-of-the-viable-system-model-vsm/
[12] https://www.jstor.org/stable/2581927
[13] https://www.alice.id.tue.nl/references/foerster-2003.pdf
[14] https://harishsnotebook.wordpress.com/2022/02/13/cybernetics-of-kindness/
[15] https://s-usih.org/2018/07/batesons-great-refusal-a-reflection/
[16] https://ejcj.orfaleacenter.ucsb.edu/wp-content/uploads/2017/06/1972.-Gregory-Bateson-Steps-to-an-Ecology-of-Mind.pdf
[17] https://www.organism.earth/library/author/gregory-bateson
[18] https://www.sciencedirect.com/science/article/pii/S2405896324002246
[19] https://dl.acm.org/doi/10.1145/3274570
[20] https://maxplanckneuroscience.org/from-cybernetics-to-ai-the-pioneering-work-of-norbert-wiener/
[21] https://www.tandfonline.com/doi/full/10.1080/00140139.2023.2281898
[22] https://pubmed.ncbi.nlm.nih.gov/36687873/
[23] https://dl.acm.org/doi/10.1145/3640543.3645199
[24] https://www.techscience.com/cmc/special_detail/LLM_integration
[25] https://pubsonline.informs.org/do/10.1287/LYTX.2024.04.09/full/
[26] https://www.liberty.edu/news/2025/03/05/liberty-law-review-symposium-addresses-impacts-of-ai-on-legal-field/
[27] https://arxiv.org/abs/2309.01105
[28] https://www.sciencedirect.com/science/article/pii/S2090123225001092
[29] https://pmc.ncbi.nlm.nih.gov/articles/PMC10828839/
[30] https://kelsienabben.substack.com/p/applying-stafford-beers-viable-system
[31] https://vsmg.lrc.org.uk/screen.php?page=preface
[32] https://academicbullying.wordpress.com/2024/03/28/stafford-beer-viable-system-model/
[33] https://library.uniteddiversity.coop/Systems_and_Networks/Viable_Systems_Model/INTRODUCTION%20TO%20THE%20VIABLE%20SYSTEM%20MODEL3.pdf
[34] https://stream.syscoi.com/2018/10/21/ethics-and-second-order-cybernetics-heinz-von-foerster/
[35] https://www.pangaro.com/hciiseminar2019/Heinz_von_Foerster-Ethics_and_Second-order_Cybernetics.pdf
[36] https://cepa.info/fulltexts/1799.pdf
[37] https://harishsnotebook.wordpress.com/tag/von-foerster/
[38] https://www.youtube.com/watch?v=GY0yq0Iyzx8
[39] https://www.honest-broker.com/p/why-gregory-bateson-matters-a8d
[40] http://www.narberthpa.com/Bale/lsbale_dop/gbtom_patp.pdf
[41] https://www.berose.fr/article2457.html
[42] https://manlius.substack.com/p/ai-cybernetics-and-complexity-unpacking
[43] https://www.linkedin.com/pulse/from-automation-autonomy-how-cybernetics-complex-systems-kullok-owntf
[44] https://www.dubberly.com/articles/the-relevance-of-cybernetics.html
[45] https://hdsr.mitpress.mit.edu/pub/aelql9qy

---
Answer from Perplexity: pplx.ai/share