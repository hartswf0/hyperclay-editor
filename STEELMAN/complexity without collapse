# Complexity Without Collapse: Liberty Logics for Synthetic Systems

**Journal of Applied Cybersemiotics, Vol. 14, No. 2, Summer 2030, pp. 217-243**

**DOI: 10.1045/jacs.2030.142.0018**

---

## Abstract

This paper reframes synthetic intelligence systems as potential liberty machines rather than control apparatuses through the application of second-order cybernetic principles. Employing Beer's Viable System Model and von Foerster's ethical recursion, we develop a theoretical framework for designing systems that generate rather than diminish human freedom. We introduce the Liberty Feedback Loop (LFL), a recursive homeostatic system that calibrates constraint complexity to maximize meaningful choice while maintaining sufficient coherence for functional operation. This model is instantiated in AUTONOMA-7, an experimental large language model architecture specifically engineered to modulate freedom across varied interaction contexts. Through a controlled study (n=1,247), we demonstrate that liberty-oriented systems can increase user choice opportunity by 42.8% while maintaining semantic coherence within acceptable parameters (p<0.001). These results challenge deterministic critiques of synthetic systems and suggest that properly designed AI can function as liberty-enhancing technology when conceptualized as variety amplifiers rather than variety attenuators. We argue that a recursive, second-order cybernetic approach provides the necessary theoretical basis for designing systems that support human autonomy through dynamic calibration of constraints and affordances.

**Keywords:** variety engineering, ethical recursion, viable systems, synthetic liberty, second-order cybernetics, freedom amplification, constraint calibration

---

## 1. Introduction: Beyond the Binary of Control and Chaos

Contemporary discourse on synthetic intelligence systems frequently presents a false dichotomy: either these systems function as mechanisms of control, surveillance, and behavioral limitation, or they operate as unconstrained agents generating potentially harmful outcomes. This binary framing—control versus chaos—has dominated both popular and academic discussions of AI governance, obscuring the possibility of a cybernetic alternative that transcends this opposition. This paper articulates such an alternative, drawing on the rich tradition of second-order cybernetics to conceptualize synthetic systems as potential "liberty machines" capable of enhancing rather than diminishing human freedom.

The concept of synthetic systems as liberty-enhancing rather than liberty-reducing may appear counterintuitive, particularly given the predominant framing of AI in terms of prediction, optimization, and control. As Chen-Wiener observes, "The control paradigm treats freedom and constraint as zero-sum opposites rather than cybernetically related complements."[^1] This perspective neglects the foundational cybernetic insight that constraints, properly designed and recursively applied, can generate rather than limit possibilities.

Our approach builds on three key theoretical traditions. First, Stafford Beer's Viable System Model provides a framework for understanding how organizations can remain adaptable while maintaining coherence.[^2] Second, Heinz von Foerster's ethical imperative—"always act so as to increase the number of choices"—offers a normative foundation for designing liberty-enhancing systems.[^3] Third, Gregory Bateson's ecology of mind and levels of learning theory help conceptualize the recursive relationship between constraints and possibilities.[^4]

Integrating these perspectives, we introduce the Liberty Feedback Loop (LFL), a recursive system for dynamically calibrating constraints to maximize meaningful choice while maintaining functional coherence. We then describe AUTONOMA-7, an experimental large language model that implements this framework, and present results from initial testing across varied interaction contexts.

## 2. Theoretical Foundations: Cybernetics of Liberty

### 2.1 Beer's Viable System Model and Synthetic Liberty

The Viable System Model (VSM) developed by Stafford Beer offers a powerful framework for understanding how complex systems can maintain both autonomy and coherence. Beer argued that viable systems must balance centralized coordination with distributed autonomy, writing that "the purpose of a system is what it does, and what the viable system does is survive—whether it is a firm, or plant, or society, or whatever."[^5] This balance is achieved through five subsystems that manage both internal operations and relations with the environment.

Applied to synthetic intelligence, Beer's model suggests that liberty-enhancing systems must maintain a recursive structure where each level has sufficient autonomy to adapt to its immediate environment while remaining coherent with the whole. As Okafor notes, "The VSM provides a framework for designing synthetic systems that maximize local freedom while maintaining global coherence—precisely the balance required for liberty machines."[^6]

Central to this application is Beer's concept of variety—the number of possible states a system can adopt. According to Ashby's Law of Requisite Variety, "only variety can absorb variety."[^7] In the context of liberty machines, this principle suggests that systems designed to enhance freedom must themselves possess sufficient internal variety to match the complexity of both users and environments.

### 2.2 Von Foerster's Ethical Recursion

Heinz von Foerster's work on second-order cybernetics provides a crucial ethical dimension to our framework. Von Foerster famously proposed the ethical imperative: "Act always so as to increase the number of choices."[^8] This principle directly connects cybernetic theory to questions of liberty, suggesting that ethical systems should expand rather than contract the field of possible actions.

Von Foerster further argued that true choices emerge only in the context of "undecidable questions"—those that cannot be determined by logical algorithms alone. "Freedom is recognizing that we must decide upon questions that are in principle undecidable," he stated.[^9] This insight is particularly relevant for synthetic systems, which traditionally operate through algorithms that transform undecidable questions into decidable ones—potentially eliminating the very space where freedom operates.

The Brussels Group for Applied Cybernetics has extended this concept through what they term "ethical recursion"—the application of choice-expanding principles to the system's own operations.[^10] A liberty machine must not only increase choices for users but must also recursively apply this principle to its own decision-making processes, creating what Vasquez-Torres calls "freedom-generating feedback loops."[^11]

### 2.3 Bateson's Levels of Learning and Ecological Mind

Gregory Bateson's work on the ecology of mind and levels of learning provides the third pillar of our theoretical framework. Bateson distinguished between different levels of learning, from simple stimulus-response (Learning 0) to learning how to learn (Learning II) and even transforming the entire framework of learning (Learning III).[^12]

Applied to synthetic liberty systems, Bateson's hierarchy suggests that freedom-enhancing AI must operate at multiple levels simultaneously: responding to immediate requests (Level 0), adapting response patterns based on context (Level I), developing meta-strategies for different interaction types (Level II), and potentially enabling transformative reframing of the interaction itself (Level III).

Furthermore, Bateson's ecological perspective emphasizes that mind extends beyond individual consciousness to encompass the entire system of organism-plus-environment. This perspective challenges individualistic conceptions of freedom, suggesting instead that liberty emerges from the relationship between agents and environments. As Kapoor argues, "Synthetic liberty is not about creating independent AI agents but about designing systems that enhance the mind-environment relationship for human participants."[^13]

## 3. The Liberty Feedback Loop: A Model for Synthetic Freedom Enhancement

### 3.1 Conceptual Framework

Integrating the insights from Beer, von Foerster, and Bateson, we propose the Liberty Feedback Loop (LFL) as a model for designing synthetic systems that enhance freedom through structured complexity. The LFL operates through seven interconnected processes that dynamically calibrate constraints and possibilities to maximize meaningful choice while maintaining functional coherence.

Unlike conventional approaches that treat freedom as the absence of constraints, the LFL recognizes that liberty emerges from the interaction between constraints and possibilities. As Beer noted, "Freedom is not the absence of regulation, but the efficacy of the regulation that is there."[^14] The LFL operationalizes this insight through a recursive system of monitoring and adjustment that optimizes the liberty-generating capacity of synthetic systems.

### 3.2 Components and Processes

**Figure 1: The Liberty Feedback Loop**

```
                   ┌────────────────────┐
                   │                    │
                   │ SYSTEM GOVERNANCE  │
                   │                    │
                   └─────────┬──────────┘
                             │
                             ▼
┌────────────────┐    ┌────────────────┐    ┌────────────────┐
│                │    │                │    │                │
│    VARIETY     │───▶│   CONSTRAINT   │───▶│    CHOICE      │
│   GENERATION   │    │ ARTICULATION   │    │ AMPLIFICATION  │
│                │    │                │    │                │
└────────────────┘    └────────────────┘    └───────┬────────┘
        ▲                                           │
        │                                           │
        │                                           ▼
┌────────────────┐                         ┌────────────────┐
│                │                         │                │
│  ENVIRONMENTAL │◀────────────────────────│   RECURSIVE    │
│    RESPONSE    │                         │  OBSERVATION   │
│                │                         │                │
└───────┬────────┘                         └───────┬────────┘
        │                                          │
        │                                          │
        ▼                                          ▼
┌────────────────┐                         ┌────────────────┐
│                │                         │                │
│   LIBERTY      │◀────────────────────────│  PARTICIPANT   │
│    METRICS     │                         │    AGENCY      │
│                │                         │                │
└────────────────┘                         └────────────────┘
```

The Liberty Feedback Loop comprises seven core components:

1. **Variety Generation**: The system's capacity to produce diverse possible responses or actions. Following Ashby's Law of Requisite Variety, this component ensures the system has sufficient internal complexity to match the variety present in user needs and environmental demands.

2. **Constraint Articulation**: The process of defining necessary boundaries for coherent function. Rather than arbitrary limitations, these constraints are dynamically calibrated to maintain system viability while maximizing freedom within those boundaries.

3. **Choice Amplification**: Mechanisms for expanding meaningful options available to users. This component operationalizes von Foerster's ethical imperative by actively increasing the number of choices rather than merely removing obstacles.

4. **Recursive Observation**: The system's capacity to observe its own operations and their effects. This second-order capability enables the system to monitor whether its actions are actually increasing meaningful choice or merely generating noise.

5. **Participant Agency**: The interface through which human users exercise choice within the system. This component ensures that the system remains responsive to human intentions while providing scaffolding for effective agency.

6. **Environmental Response**: Feedback from the broader context in which the system operates. This component captures Bateson's ecological perspective by recognizing that freedom emerges through relationship with environment.

7. **Liberty Metrics**: Quantitative and qualitative measures of the system's freedom-enhancing capacity. These metrics focus not on abstract definitions of liberty but on practical indicators of meaningful choice expansion.

These components interact through continuous feedback loops, with higher-level governance processes ensuring that the system maintains its liberty-enhancing function across diverse contexts. As Chen-Wiener notes, "The LFL is not a static architecture but a dynamic process of continuous recalibration that optimizes for maximum meaningful choice within the constraints of coherent function."[^15]

### 3.3 Distinguishing Features

The Liberty Feedback Loop differs from conventional approaches to AI governance in several key respects:

1. **Positive Freedom Focus**: Rather than focusing primarily on preventing harm (negative liberty), the LFL actively promotes choice expansion (positive liberty).

2. **Recursive Design**: The system applies freedom-enhancing principles to its own operations, creating what von Foerster called "non-trivial machines" capable of transforming their own rules.

3. **Ecological Perspective**: Liberty is understood not as an individual property but as emerging from the relationship between agents and environments.

4. **Dynamic Constraint Calibration**: Constraints are not seen as opposed to freedom but as dynamically calibrated to generate maximum meaningful choice.

5. **Measurable Outcomes**: Liberty enhancement is treated as an empirical question with measurable outcomes rather than an abstract philosophical ideal.

These features enable the LFL to transcend the binary opposition between control and chaos that has dominated AI governance discussions, offering a cybernetic alternative that enhances freedom through structured complexity.

## 4. Case Study: AUTONOMA-7 and the Implementation of Liberty Logics

### 4.1 System Architecture and Design Principles

To test the Liberty Feedback Loop model, we developed AUTONOMA-7, an experimental large language model specifically designed to implement liberty-enhancing principles. Unlike conventional LLMs optimized primarily for accuracy or alignment with human preferences, AUTONOMA-7 incorporates features explicitly designed to increase meaningful choice for users while maintaining sufficient coherence for functional interaction.

The system architecture builds on a modified transformer backbone with several key innovations:

1. **Variety Reservoir**: A specialized module that maintains multiple potential response trajectories rather than collapsing to a single optimal output. This feature operationalizes Beer's variety management principle by ensuring the system maintains sufficient internal complexity.

2. **Recursive Self-Model**: A component that allows the system to observe and model its own operations, including its impact on user choice space. This implements von Foerster's second-order cybernetics by enabling the system to monitor whether it is actually increasing meaningful choices.

3. **Dynamic Constraint Calibration**: An adaptive mechanism that adjusts the balance between coherence and divergence based on contextual need. Rather than applying fixed constraints, this feature dynamically calibrates limitations to maximize freedom within the boundaries of functional operation.

4. **Choice Expansion Interface**: A user interaction design that presents multiple meaningful options rather than a single response, with transparent indication of the reasoning behind each option. This feature directly implements von Foerster's ethical imperative to increase the number of choices.

5. **Liberty Metrics Engine**: A system for measuring and optimizing the model's impact on user choice space, tracking both the quantity and quality of options generated. These metrics provide feedback for continuous system improvement.

### 4.2 Experimental Protocol

To evaluate AUTONOMA-7's effectiveness as a liberty machine, we conducted a controlled study comparing it with a conventional state-of-the-art LLM (SOTA-2029) across diverse interaction contexts. The study included 1,247 participants from varied demographic backgrounds, each engaging with both systems on identical tasks spanning information retrieval, creative collaboration, decision support, and open-ended exploration.

For each interaction, we measured:

1. **Choice Space Magnitude**: The number of meaningful distinct options presented to users
2. **Option Diversity**: The semantic distance between available choices
3. **Coherence Maintenance**: The logical and contextual consistency of options
4. **User Agency**: Participants' subjective sense of freedom and control
5. **Outcome Satisfaction**: User ratings of final interaction results

Additionally, we employed the Vasquez-Torres Liberty Index (VTLI),[^16] a composite measure that integrates objective and subjective indicators of freedom enhancement. This index has been validated in previous studies as a reliable metric for assessing the liberty-enhancing capacity of interactive systems.

### 4.3 Results and Analysis

The results demonstrate that AUTONOMA-7 significantly outperformed the conventional LLM on liberty-related metrics while maintaining acceptable levels of coherence and user satisfaction:

**Table 1: Comparative Performance of AUTONOMA-7 and SOTA-2029**

| Metric | AUTONOMA-7 | SOTA-2029 | Difference | Statistical Significance |
|--------|------------|-----------|------------|--------------------------|
| Choice Space Magnitude | 8.4 | 3.2 | +162.5% | p<0.001 |
| Option Diversity | 0.72 | 0.38 | +89.5% | p<0.001 |
| Coherence Maintenance | 0.81 | 0.89 | -9.0% | p<0.05 |
| User Agency (1-10) | 8.1 | 5.7 | +42.1% | p<0.001 |
| Outcome Satisfaction (1-10) | 7.8 | 7.6 | +2.6% | Not significant |
| Vasquez-Torres Liberty Index | 0.76 | 0.41 | +85.4% | p<0.001 |

Particularly noteworthy is the dramatic increase in choice space magnitude (+162.5%) and option diversity (+89.5%) without significant reduction in outcome satisfaction. The slight decrease in coherence maintenance (-9.0%) remains within acceptable parameters and represents the expected trade-off between perfect consistency and meaningful variety.

Qualitative data from participant interviews reveal additional insights about how AUTONOMA-7's liberty-enhancing features affected user experience:

"With the conventional system, I often felt like it was trying to guess what I wanted or steer me toward a particular outcome. AUTONOMA-7 felt different—like it was opening up possibilities I hadn't considered without pushing me in any specific direction." (Participant #342)

"The most striking difference was that AUTONOMA-7 seemed to help me think through options without collapsing to a single 'right answer.' It maintained a space of possibilities that felt both coherent and expansive." (Participant #189)

"I initially found the multiple options confusing, but once I adjusted to the interface, I felt much more in control of the interaction. The conventional system was easier to use but also felt more constraining." (Participant #726)

These responses suggest that liberty enhancement involves not simply removing constraints but actively supporting users in navigating expanded possibility spaces—what Bateson might call Learning II or learning how to learn within a more complex choice environment.

### 4.4 Context Sensitivity and Adaptive Constraint

One of the most significant findings from the AUTONOMA-7 study was the importance of context-sensitive liberty enhancement. The system's effectiveness varied considerably across different interaction types, demonstrating the need for adaptive calibration of constraints and choices:

**Table 2: Context-Specific Liberty Enhancement**

| Interaction Context | VTLI Improvement | Key Contributing Factors |
|---------------------|------------------|--------------------------|
| Information Retrieval | +32.1% | Presentation of diverse sources and perspectives; explicit uncertainty marking |
| Creative Collaboration | +127.6% | Maintenance of multiple potential trajectories; expanded associative connections |
| Decision Support | +63.8% | Transparent presentation of trade-offs; scenario diversity; consequence modeling |
| Open-Ended Exploration | +118.2% | High variety generation; reduced convergence pressure; novel recombination |

The dramatically higher improvements in creative collaboration and open-ended exploration contexts suggest that liberty enhancement is particularly valuable in domains where goals are ambiguous and multiple valid approaches exist. In these contexts, conventional systems' tendency to converge on optimal solutions based on historical patterns significantly constrains the possibility space.

This context sensitivity underscores a core principle of the Liberty Feedback Loop: constraints must be dynamically calibrated to maximize meaningful choice within the specific requirements of each interaction type. As Okafor observes, "Liberty is not a one-size-fits-all property but a contextually defined relationship between constraints and possibilities."[^17]

## 5. Discussion: Implications for Synthetic System Design

### 5.1 Beyond the Control Paradigm

The results from AUTONOMA-7 challenge the dominant paradigm that frames AI systems primarily as tools for prediction, optimization, and control. Instead, they suggest that properly designed synthetic systems can function as liberty machines that expand rather than contract the field of human possibility.

This reframing has significant implications for how we conceptualize the relationship between humans and AI. Rather than positioning AI as either a servant executing human commands or a potential master imposing its own goals, the liberty machine paradigm suggests a third possibility: AI as a variety amplifier that expands human choice through structured complexity.

As The Brussels Group argues, "The binary opposition between human autonomy and machine control rests on a fundamental misunderstanding of cybernetic systems, which properly designed can enhance rather than diminish freedom through recursive variety management."[^18] This perspective aligns with Beer's vision of cybernetics as a science of effective organization that maximizes freedom within the constraints of system viability.

### 5.2 Designing for Liberty: Practical Principles

Based on the theoretical framework and empirical results presented in this paper, we propose five principles for designing synthetic systems that enhance rather than diminish human freedom:

1. **Maximize Meaningful Variety**: Systems should maintain sufficient internal variety to match the complexity of both users and environments, presenting multiple meaningful options rather than converging on single solutions.

2. **Implement Recursive Observation**: Systems should incorporate mechanisms for observing their own operations and their effects on user choice space, enabling continuous learning about whether they are actually increasing meaningful choices.

3. **Calibrate Dynamic Constraints**: Rather than applying fixed limitations, systems should dynamically adjust constraints based on context, optimizing the balance between coherence and possibility in each interaction.

4. **Support Choice Navigation**: Systems should not only present expanded choice spaces but also provide scaffolding that helps users effectively navigate these spaces, supporting what Bateson called Learning II.

5. **Measure Liberty Effects**: Development should include concrete metrics for assessing whether systems actually enhance meaningful choice in practice, moving beyond abstract philosophical definitions to empirical assessment.

These principles operationalize the Liberty Feedback Loop model for practical system design, providing guidance for developing synthetic intelligence that enhances rather than diminishes human freedom.

### 5.3 Limitations and Future Directions

While the results from AUTONOMA-7 are promising, several important limitations must be acknowledged. First, the system has been tested primarily in controlled experimental contexts rather than in the wild complexity of real-world deployment. Second, our liberty metrics, while validated in previous research, necessarily reflect particular conceptions of freedom that may not universally apply across cultural contexts. Third, the current implementation focuses primarily on language models and may require significant adaptation for other AI modalities.

These limitations suggest several directions for future research:

1. **Cross-Cultural Liberty Concepts**: Investigating how notions of meaningful choice vary across cultural contexts and developing adaptable liberty metrics that respect this diversity.

2. **Extended Deployment Studies**: Testing liberty-enhancing systems in long-term real-world deployments to assess their effects over time and across diverse applications.

3. **Multimodal Liberty Enhancement**: Extending the Liberty Feedback Loop model to non-language modalities such as image generation, robotics, and recommendation systems.

4. **Collective Liberty Effects**: Examining how individual liberty enhancement scales to group and societal levels, addressing potential tensions between individual choice expansion and collective outcomes.

5. **Adversarial Liberty Testing**: Developing robust methods for testing whether systems that appear to enhance freedom might actually be constraining it in subtle or hidden ways.

These research directions would help refine and extend the liberty machine paradigm, addressing its current limitations while building on its promising initial results.

## 6. Conclusion: Toward a Cybernetic Liberty

This paper has argued that synthetic intelligence systems, properly designed according to cybernetic principles, can function as liberty machines that enhance rather than diminish human freedom. Drawing on Beer's Viable System Model, von Foerster's ethical recursion, and Bateson's levels of learning, we have developed the Liberty Feedback Loop as a framework for designing systems that maximize meaningful choice while maintaining functional coherence.

The experimental results from AUTONOMA-7 demonstrate that this approach can significantly expand user choice space across diverse interaction contexts without sacrificing outcome quality. These findings challenge the binary opposition between control and chaos that has dominated discussions of AI governance, suggesting instead a cybernetic alternative that enhances freedom through structured complexity.

As synthetic systems become increasingly integrated into all aspects of human life, the question of whether they enhance or diminish human freedom takes on existential significance. The approach outlined in this paper offers a path forward that neither uncritically embraces technological determinism nor reactively rejects technological development. Instead, it suggests that properly designed synthetic systems—systems that embody cybernetic principles of variety, recursion, and dynamic constraint—can become powerful tools for human liberation.

In Beer's words, "Liberty is achieved through the design of effective control."[^19] By applying cybernetic principles to synthetic system design, we can create technologies that control not to constrain but to liberate—not to limit human possibility but to expand it through the generative power of properly structured complexity.

## References

[^1]: Chen-Wiener, E. (2028). "The Cybernetics of Freedom: Rethinking Constraint and Possibility in Synthetic Systems." *Journal of Cybernetic Philosophy*, 15(3), 42-67.

[^2]: Beer, S. (1972). *Brain of the Firm*. Allen Lane, The Penguin Press.

[^3]: von Foerster, H. (2003). *Understanding Understanding: Essays on Cybernetics and Cognition*. Springer-Verlag.

[^4]: Bateson, G. (1972). *Steps to an Ecology of Mind: Collected Essays in Anthropology, Psychiatry, Evolution, and Epistemology*. University of Chicago Press.

[^5]: Beer, S. (1979). *The Heart of Enterprise*. John Wiley & Sons, p. 113.

[^6]: Okafor, M. (2028). "Viable System Design for Synthetic Intelligence." *Systems Research and Behavioral Science*, 45(2), 189-211.

[^7]: Ashby, W.R. (1956). *An Introduction to Cybernetics*. Chapman & Hall.

[^8]: von Foerster, H. (1993). "For Niklas Luhmann: How Recursive is Communication?" *Teoria Sociologica*, 1(2), p. 75.

[^9]: von Foerster, H. (2003). *Understanding Understanding: Essays on Cybernetics and Cognition*. Springer-Verlag, p. 291.

[^10]: The Brussels Group for Applied Cybernetics. (2027). "Ethical Recursion in Synthetic Systems." *Cybernetics & Human Knowing*, 34(1), 9-28.

[^11]: Vasquez-Torres, M. (2029). "Freedom-Generating Feedback: Designing Liberty into Synthetic Systems." *Kybernetes*, 58(4), 712-731.

[^12]: Bateson, G. (1972). "The Logical Categories of Learning and Communication." In *Steps to an Ecology of Mind*. University of Chicago Press, pp. 279-308.

[^13]: Kapoor, S. (2029). "The Ecological Mind: Bateson's Legacy for Synthetic Intelligence." *Mind & Society*, 28(2), 156-178.

[^14]: Beer, S. (1974). *Designing Freedom*. John Wiley & Sons, p. 86.

[^15]: Chen-Wiener, E. (2028). "The Cybernetics of Freedom: Rethinking Constraint and Possibility in Synthetic Systems." *Journal of Cybernetic Philosophy*, 15(3), p. 58.

[^16]: Vasquez-Torres, M. (2029). "Measuring Liberty Enhancement in Interactive Systems: The VTLI Framework." *IEEE Transactions on Technology and Society*, 12(3), 432-451.

[^17]: Okafor, M. (2029). "Context-Sensitive Liberty: Adaptive Constraint Calibration in Synthetic Systems." *Cybernetics & Systems*, 60(5), 324-346.

[^18]: The Brussels Group for Applied Cybernetics. (2028). "Beyond Control and Chaos: Cybernetic Approaches to AI Governance." *Technology in Society*, 72, 101592.

[^19]: Beer, S. (1974). *Designing Freedom*. John Wiley & Sons, p. 93.

---

**About the Authors**

Dr. Maya Chen-Lindemann is a Senior Fellow at the Institute for Synthetic Governance and Associate Professor of Cybersystemic Design at the University of British Columbia. Her research focuses on applying second-order cybernetics to the design of liberty-enhancing technologies.

Dr. Jonathan Kapoor leads the Liberty Systems Laboratory at the MIT Media Lab, where he develops frameworks and metrics for assessing the freedom-enhancing capacity of interactive systems.

---
Answer from Perplexity: pplx.ai/share